{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1183191,"sourceType":"datasetVersion","datasetId":672399}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetV2B0, ResNet50V2, DenseNet121\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom warnings import filterwarnings\n\n# Suppress warnings\nfilterwarnings('ignore')\n\n# Global Constants\ndataset_path = '/kaggle/input/the-iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset'\noutput_path = '/kaggle/working/'  # Path to save models in Kaggle output\nlabels = ['bengin', 'malignant', 'normal']\nimage_size = 150\nbatch_size = 32\nepochs = 2\n\n# Function to load and preprocess data\ndef load_data(dataset_path, labels, image_size):\n    X_data = []\n    y_data = []\n    \n    for label in labels:\n        folder_path = os.path.join(dataset_path, f'{label.capitalize()} cases')\n        for img_name in tqdm(os.listdir(folder_path)):\n            img_path = os.path.join(folder_path, img_name)\n            img = cv2.imread(img_path)\n            if img is None:\n                continue\n            img = cv2.resize(img, (image_size, image_size))\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Ensure the image is in RGB format\n            X_data.append(img)\n            y_data.append(label)\n    \n    X_data = np.array(X_data)\n    y_data = np.array(y_data)\n    \n    # Shuffle data here\n    X_data, y_data = shuffle(X_data, y_data, random_state=101)\n    \n    return X_data, y_data\n\n# Load and split data\nX_data, y_data = load_data(dataset_path, labels, image_size)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=101, stratify=y_data)\n\n# Convert labels to categorical\ny_train = tf.keras.utils.to_categorical([labels.index(i) for i in y_train], num_classes=len(labels))\ny_test = tf.keras.utils.to_categorical([labels.index(i) for i in y_test], num_classes=len(labels))\n\n# Function to build and train individual models\ndef build_and_train_model(base_model, model_name, X_train, y_train):\n    base_model = base_model(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n    model = tf.keras.models.Sequential([\n        base_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(len(labels), activation='softmax')  # Number of classes\n    ])\n    \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    tensorboard = TensorBoard(log_dir=f'logs/{model_name}')\n    checkpoint = ModelCheckpoint(os.path.join(output_path, f\"{model_name}.keras\"), monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2, min_delta=0.001, mode='max', verbose=1)\n    \n    history = model.fit(X_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size,\n                        callbacks=[tensorboard, checkpoint, reduce_lr])\n    \n    return model, history\n\n# Function to build and train ensemble model\ndef build_ensemble_model(models, X_train, y_train):\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    outputs = [model(inputs) for model in models]\n    averaged_outputs = tf.keras.layers.Average()(outputs)\n    \n    ensemble_model = tf.keras.models.Model(inputs=inputs, outputs=averaged_outputs)\n    ensemble_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    tensorboard = TensorBoard(log_dir='logs/Ensemble')\n    checkpoint = ModelCheckpoint(os.path.join(output_path, \"Ensemble.keras\"), monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2, min_delta=0.001, mode='max', verbose=1)\n    \n    history = ensemble_model.fit(X_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size,\n                                 callbacks=[tensorboard, checkpoint, reduce_lr])\n    \n    return ensemble_model, history\n\n# Build and train individual models\nmodel_builders = [EfficientNetV2B0, ResNet50V2, DenseNet121]\ntrained_models = []\nhistories = {}\n\nfor model_builder in model_builders:\n    model_name = model_builder.__name__\n    model, history = build_and_train_model(model_builder, model_name, X_train, y_train)\n    trained_models.append(model)\n    histories[model_name] = history\n\n# Save each individual model\nfor model_builder in model_builders:\n    model_name = model_builder.__name__\n    model.save(os.path.join(output_path, f\"{model_name}.keras\"))\n\n# Build and train ensemble model using trained individual models\nensemble_model, ensemble_history = build_ensemble_model(trained_models, X_train, y_train)\nmodels = {\"Ensemble\": ensemble_model}\nhistories[\"Ensemble\"] = ensemble_history\n\n# Save the ensemble model\nensemble_model.save(os.path.join(output_path, \"Ensemble.keras\"))\n\n# Function to print model probabilities for a given test image\ndef print_model_probabilities(models, X_test, labels):\n    test_image = X_test[0:1]  # Take the first image for demonstration\n    print(\"Probabilities for the first test image:\")\n    for model_name, model in models.items():\n        probabilities = model.predict(test_image)[0]\n        print(f\"\\nModel: {model_name}\")\n        for i, label in enumerate(labels):\n            print(f\"Probability of {label}: {probabilities[i]:.4f}\")\n\nprint_model_probabilities(models, X_test, labels)\n\n# Function to plot training history for each model\ndef plot_history(histories):\n    for model_name, history in histories.items():\n        plt.figure(figsize=(14, 5))\n        \n        # Plot accuracy\n        plt.subplot(1, 2, 1)\n        plt.plot(history.history['accuracy'], label='Training Accuracy')\n        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n        plt.xlabel('Epochs')\n        plt.ylabel('Accuracy')\n        plt.title(f'{model_name} - Training and Validation Accuracy')\n        plt.legend()\n        plt.grid(True)\n        \n        # Plot loss\n        plt.subplot(1, 2, 2)\n        plt.plot(history.history['loss'], label='Training Loss')\n        plt.plot(history.history['val_loss'], label='Validation Loss')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.title(f'{model_name} - Training and Validation Loss')\n        plt.legend()\n        plt.grid(True)\n        \n        plt.tight_layout()\n        plt.show()\n\nplot_history(histories)\n\n# Function to evaluate models and plot confusion matrix\ndef evaluate_model(model, X_test, y_test, model_name):\n    y_pred = np.argmax(model.predict(X_test), axis=-1)\n    y_true = np.argmax(y_test, axis=-1)\n    \n    print(f\"Classification Report for {model_name}:\")\n    print(classification_report(y_true, y_pred, target_names=labels, digits=4))  # Display with 4 decimal places\n    \n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Convert confusion matrix to percentages\n    cm_percentage = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # Plot confusion matrix with percentages\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=labels)\n    disp.plot(cmap=plt.cm.Blues, values_format='.2f')  # Display with 2 decimal places\n    plt.title(f'{model_name} - Confusion Matrix (Percentage)')\n    plt.show()\n\n# Evaluate ensemble model and plot confusion matrix\nevaluate_model(ensemble_model, X_test, y_test, \"Ensemble\")\n\n# Print the number of parameters for the ensemble model\nprint(f\"Ensemble model has {ensemble_model.count_params()} parameters.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import clear_output\n\n# Function to predict uploaded image\ndef img_pred(uploader):\n    if uploader.value:\n        # Convert uploaded file to image format\n        content = uploader.value[next(iter(uploader.value))]['content']\n        img = np.frombuffer(content, dtype=np.uint8)\n        img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n        \n        # Preprocess the image for prediction\n        img_resized = cv2.resize(img, (image_size, image_size))\n        img_resized = np.expand_dims(img_resized, axis=0)\n        \n        # Get predictions from ensemble model\n        predictions = ensemble_model.predict(img_resized)\n        \n        # Display the prediction results\n        for i, label in enumerate(labels):\n            print(f\"Probability of {label}: {predictions[0][i]:.4f}\")\n        \n        # Show the uploaded image\n        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        plt.title(\"Uploaded Image\")\n        plt.axis('off')\n        plt.show()\n    else:\n        print(\"No image uploaded!\")\n\n# Create the file uploader widget\nuploader = widgets.FileUpload(accept='image/*', multiple=False)\n\n# Create the prediction button and output widget\nbutton = widgets.Button(description='Predict')\nout = widgets.Output()\n\n# Define the button click event\ndef on_button_clicked(_):\n    with out:\n        clear_output()  # Clear the previous output\n        try:\n            img_pred(uploader)\n        except Exception as e:\n            print(f\"Error: {e}\")\n            print(\"No Image Uploaded/Invalid Image File\")\n\n# Attach the button click event to the function\nbutton.on_click(on_button_clicked)\n\n# Display the widgets\ndisplay(widgets.VBox([uploader, button, out]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetV2B0, ResNet50V2, DenseNet121\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom warnings import filterwarnings\n\n# Suppress warnings to keep the output clean\nfilterwarnings('ignore')\n\n# Global Constants\ndataset_path = '/kaggle/input/the-iqothnccd-lung-cancer-dataset/The IQ-OTHNCCD lung cancer dataset'\noutput_path = '/kaggle/working/'  # Path to save models in Kaggle output\n\n# Define labels for the dataset\nlabels = ['bengin', 'malignant', 'normal']  # Classes in the dataset\n\n# Define image parameters\nimage_size = 150  # Size to which images will be resized\nbatch_size = 32  # Number of samples per gradient update\nepochs = 2  # Number of epochs for training\n\n# Function to load and preprocess data\ndef load_data(dataset_path, labels, image_size):\n    X_data = []  # List to hold image data\n    y_data = []  # List to hold labels\n    \n    # Loop through each label (class)\n    for label in labels:\n        # Construct the folder path for the current label\n        folder_path = os.path.join(dataset_path, f'{label.capitalize()} cases')\n        \n        # Loop through each image in the folder\n        for img_name in tqdm(os.listdir(folder_path)):\n            img_path = os.path.join(folder_path, img_name)\n            img = cv2.imread(img_path)  # Read the image\n            \n            if img is None:\n                continue  # Skip if the image is not found\n            \n            # Resize the image\n            img = cv2.resize(img, (image_size, image_size))\n            \n            # Convert image to RGB format\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            # Append processed image and its label to lists\n            X_data.append(img)\n            y_data.append(label)\n    \n    # Convert lists to NumPy arrays\n    X_data = np.array(X_data)\n    y_data = np.array(y_data)\n    \n    # Shuffle data here for randomness\n    X_data, y_data = shuffle(X_data, y_data, random_state=101)\n    \n    return X_data, y_data\n\n# Load data from the specified dataset path\nX_data, y_data = load_data(dataset_path, labels, image_size)\n\n# Split data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=101, stratify=y_data)\n\n# Convert labels to categorical format for training\ny_train = tf.keras.utils.to_categorical([labels.index(i) for i in y_train], num_classes=len(labels))\ny_test = tf.keras.utils.to_categorical([labels.index(i) for i in y_test], num_classes=len(labels))\n\n# Function to build and train individual models\ndef build_and_train_model(base_model, model_name, X_train, y_train):\n    # Initialize the base model with ImageNet weights\n    base_model = base_model(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n    \n    # Build the full model architecture\n    model = tf.keras.models.Sequential([\n        base_model,  # Add the base model\n        tf.keras.layers.GlobalAveragePooling2D(),  # Pooling layer to reduce dimensions\n        tf.keras.layers.Dropout(0.5),  # Dropout layer for regularization\n        tf.keras.layers.Dense(len(labels), activation='softmax')  # Output layer for classification\n    ])\n    \n    # Compile the model with loss function and optimizer\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    # Set up callbacks for training\n    tensorboard = TensorBoard(log_dir=f'logs/{model_name}')  # For TensorBoard logging\n    checkpoint = ModelCheckpoint(os.path.join(output_path, f\"{model_name}.keras\"),\n                                 monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2,\n                                   min_delta=0.001, mode='max', verbose=1)\n    \n    # Train the model with training data\n    history = model.fit(X_train, y_train, validation_split=0.1, epochs=epochs,\n                        batch_size=batch_size, callbacks=[tensorboard, checkpoint, reduce_lr])\n    \n    return model, history\n\n# Function to build and train an ensemble model\ndef build_ensemble_model(models, X_train, y_train):\n    # Define input layer for the ensemble model\n    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n    \n    # Collect outputs from each individual model\n    outputs = []\n    for model in models:\n        output = model(inputs)  # Get output from the model\n        outputs.append(output)  # Append to outputs list\n    \n    # Average the outputs from all models\n    averaged_outputs = tf.keras.layers.Average()(outputs)\n    \n    # Construct the ensemble model\n    ensemble_model = tf.keras.models.Model(inputs=inputs, outputs=averaged_outputs)\n    \n    # Compile the ensemble model\n    ensemble_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    # Set up callbacks for training the ensemble model\n    tensorboard = TensorBoard(log_dir='logs/Ensemble')\n    checkpoint = ModelCheckpoint(os.path.join(output_path, \"Ensemble.keras\"),\n                                 monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2,\n                                   min_delta=0.001, mode='max', verbose=1)\n    \n    # Train the ensemble model\n    history = ensemble_model.fit(X_train, y_train, validation_split=0.1, epochs=epochs,\n                                 batch_size=batch_size, callbacks=[tensorboard, checkpoint, reduce_lr])\n    \n    return ensemble_model, history\n\n# Build and train individual models\nmodel_builders = [EfficientNetV2B0, ResNet50V2, DenseNet121]\ntrained_models = []  # List to store trained models\nhistories = {}  # Dictionary to store training histories\n\n# Loop through model builders to train each model\nfor model_builder in model_builders:\n    model_name = model_builder.__name__  # Get the model name\n    print(f\"Training model: {model_name}\")  # Log the model being trained\n    \n    model, history = build_and_train_model(model_builder, model_name, X_train, y_train)\n    \n    # Store the trained model and its training history\n    trained_models.append(model)\n    histories[model_name] = history\n\n# Save each individual model to the output path\nfor model_builder in model_builders:\n    model_name = model_builder.__name__\n    model.save(os.path.join(output_path, f\"{model_name}.keras\"))  # Save model\n    print(f\"Saved model: {model_name}.keras\")  # Log the model saving\n\n# Build and train ensemble model using trained individual models\nprint(\"Building and training ensemble model...\")  # Log the start of ensemble training\nensemble_model, ensemble_history = build_ensemble_model(trained_models, X_train, y_train)\n\n# Store the ensemble model in a dictionary for reference\nmodels = {\"Ensemble\": ensemble_model}\nhistories[\"Ensemble\"] = ensemble_history  # Store history of ensemble training\n\n# Save the ensemble model\nensemble_model.save(os.path.join(output_path, \"Ensemble.keras\"))\nprint(\"Saved ensemble model: Ensemble.keras\")  # Log the saving of ensemble model\n\n# Function to print model probabilities for a given test image\ndef print_model_probabilities(models, X_test, labels):\n    test_image = X_test[0:1]  # Take the first image for demonstration\n    print(\"Probabilities for the first test image:\")\n    \n    # Loop through each model and display its predictions\n    for model_name, model in models.items():\n        print(f\"\\nPredicting probabilities using model: {model_name}\")  # Log model prediction\n        probabilities = model.predict(test_image)[0]  # Get predicted probabilities\n        \n        # Display probabilities for each label\n        for i, label in enumerate(labels):\n            print(f\"Probability of {label}: {probabilities[i]:.4f}\")\n\n# Print probabilities for the first test image\nprint_model_probabilities(models, X_test, labels)\n\n# Function to plot training history for each model\ndef plot_history(histories):\n    # Loop through each model's history for plotting\n    for model_name, history in histories.items():\n        plt.figure(figsize=(14, 5))  # Set figure size\n        \n        # Plot accuracy\n        plt.subplot(1, 2, 1)  # Create subplot for accuracy\n        plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n        plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n        plt.xlabel('Epochs')  # X-axis label\n        plt.ylabel('Accuracy')  # Y-axis label\n        plt.title(f'{model_name} - Training and Validation Accuracy')  # Title\n        plt.legend()  # Show legend\n        plt.grid(True)  # Add grid for better readability\n        \n        # Plot loss\n        plt.subplot(1, 2, 2)  # Create subplot for loss\n        plt.plot(history.history['loss'], label='Training Loss', color='red')\n        plt.plot(history.history['val_loss'], label='Validation Loss', color='green')\n        plt.xlabel('Epochs')  # X-axis label\n        plt.ylabel('Loss')  # Y-axis label\n        plt.title(f'{model_name} - Training and Validation Loss')  # Title\n        plt.legend()  # Show legend\n        plt.grid(True)  # Add grid for better readability\n        \n        plt.tight_layout()  # Adjust layout for subplots\n        plt.show()  # Display the plots\n\n# Call the function to plot training histories for all models\nprint(\"Plotting training histories...\")  # Log the start of plotting\nplot_history(histories)\n\n# Function to evaluate models and plot confusion matrix\ndef evaluate_model(model, X_test, y_test, model_name):\n    print(f\"Evaluating model: {model_name}\")  # Log evaluation\n    y_pred = np.argmax(model.predict(X_test), axis=-1)  # Get predictions\n    y_true = np.argmax(y_test, axis=-1)  # Get true labels\n    \n    print(f\"Classification Report for {model_name}:\")  # Print classification report header\n    print(classification_report(y_true, y_pred, target_names=labels, digits=4))  # Display with 4 decimal places\n    \n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Convert confusion matrix to percentages\n    cm_percentage = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # Plot confusion matrix with percentages\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=labels)\n    disp.plot(cmap=plt.cm.Blues, values_format='.2f')  # Display with 2 decimal places\n    plt.title(f'{model_name} - Confusion Matrix (Percentage)')  # Title\n    plt.show()  # Show the plot\n\n# Evaluate each individual model and plot confusion matrix\nfor model in trained_models:\n    model_name = model.name  # Get model name\n    evaluate_model(model, X_test, y_test, model_name)\n\n# Evaluate ensemble model and plot confusion matrix\nevaluate_model(ensemble_model, X_test, y_test, \"Ensemble\")\n\n# Print the number of parameters for the ensemble model\nprint(f\"Ensemble model has {ensemble_model.count_params()} parameters.\")  # Log parameter count\n","metadata":{},"execution_count":null,"outputs":[]}]}